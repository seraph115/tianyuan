# Tianyuan Project

## ğŸ•·ï¸ åˆ†å¸ƒå¼çˆ¬è™«å¹³å°ï¼ˆScrapy + Kafka + Airflowï¼‰

æœ¬é¡¹ç›®ä¸ºä¸€ä¸ªå¯æ‰©å±•çš„åˆ†å¸ƒå¼çˆ¬è™«å¹³å°ï¼Œé›†æˆ **Scrapy çˆ¬è™«æ¡†æ¶**ã€**Kafka 4.1.0ï¼ˆKRaft æ¨¡å¼ï¼‰æ¶ˆæ¯é˜Ÿåˆ—**ã€**Redis ç¼“å­˜é˜Ÿåˆ—** ä»¥åŠ **Airflow 3.1.0 è°ƒåº¦ç³»ç»Ÿ**ã€‚é€šè¿‡å®¹å™¨åŒ–éƒ¨ç½²ï¼ˆDocker Composeï¼‰ï¼Œæ”¯æŒå¤šèŠ‚ç‚¹çˆ¬å–ã€ä»»åŠ¡è°ƒåº¦ä¸æ•°æ®æµå¼å¤„ç†ï¼Œé€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®é‡‡é›†åœºæ™¯ã€‚

---

### âš™ï¸ æŠ€æœ¯æ ˆ

| æ¨¡å— | è¯´æ˜ |
|------|------|
| **Scrapy 2.13.3** | Python çˆ¬è™«æ¡†æ¶ï¼Œè´Ÿè´£æ•°æ®é‡‡é›†ä¸è§£æ |
| **Kafka 4.1.0 (KRaft)** | åˆ†å¸ƒå¼æ¶ˆæ¯é˜Ÿåˆ—ï¼Œç”¨äºä»»åŠ¡åˆ†å‘ä¸ç»“æœæ±‡èš |
| **Redis 7.x** | ç¼“å­˜ä¸ä»»åŠ¡é˜Ÿåˆ—è¾…åŠ© |
| **Airflow 3.1.0** | è°ƒåº¦ç³»ç»Ÿï¼Œç”¨äºçˆ¬è™«ä»»åŠ¡ç¼–æ’ä¸é‡æŠ“ç­–ç•¥ |
| **Docker Compose** | ä¸€é”®éƒ¨ç½²ä¸å®¹å™¨ç¼–æ’ |

---

### ğŸ“ ç›®å½•ç»“æ„

```bash
crawler-platform/
â”œâ”€ docker-compose.yml                   # Redis + Kafka (KRaft) + Scrapy èŠ‚ç‚¹
â”œâ”€ docker-compose.airflow.yml           # Airflow 3.1.0ï¼ˆç‹¬ç«‹éƒ¨ç½²ï¼‰
â”œâ”€ spider/
â”‚  â”œâ”€ Dockerfile                        # Scrapy é•œåƒæ„å»ºæ–‡ä»¶
â”‚  â”œâ”€ requirements.txt                  # Python ä¾èµ–åŒ…æ¸…å•
â”‚  â”œâ”€ scrapy.cfg                        # Scrapy é…ç½®å…¥å£
â”‚  â””â”€ proj/
â”‚     â”œâ”€ settings.py                    # çˆ¬è™«å…¨å±€è®¾ç½®
â”‚     â”œâ”€ pipelines.py                   # æ•°æ®å¤„ç†ä¸å­˜å‚¨é€»è¾‘
â”‚     â””â”€ spiders/
â”‚        â””â”€ example_spider.py           # ç¤ºä¾‹çˆ¬è™«
â””â”€ airflow/
   â””â”€ dags/
      â””â”€ seed_and_recrawl.py            # Airflow DAGï¼šç§å­æŠ•é€’ + å®šæœŸé‡æŠ“
